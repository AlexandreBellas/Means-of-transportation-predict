{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mineração Estatística de Dados\n",
    "## Projeto 1: Pré-processamento de dados e classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alunos\n",
    "- Alexandre Batistellas Bellas&emsp;&emsp;&emsp;&nbsp;&emsp;9763168\n",
    "- Juan Carlos Elias Obando Valdivia&emsp;&nbsp;7487156"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 – Considere a base de dados (arquivo dataset_5secondWindow%5B1%5D.csv):\n",
    "## https://www.kaggle.com/fschwartzer/tmd-dataset-5-seconds-sliding-window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 – Realize o pré-processamento dos dados: Verifque se há NaN ou outros erros no dados. Selecione apenas os atributos relevantes e numéricos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura e pre-processamento dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ler o conjunto de dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "random.seed(1)\n",
    "\n",
    "#Lendo o arquivo CSV\n",
    "features = pd.read_csv(\"data/dataset_5secondWindow%5B1%5D.csv\", header=(0))\n",
    "print(features.shape)\n",
    "\n",
    "features.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente, vamos remover as linhas com \"?\" e com \"NaN\" do arquivo, apagando as linhas que contém esse problema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.replace('?', np.nan)\n",
    "features = features.dropna()\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos remover as linhas duplicadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.duplicated()\n",
    "features = features.drop_duplicates()\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtendo as classes únicas no conjunto de dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classes = pd.unique(features[features.columns[-1]]) #name of the classes\n",
    "classes = np.array(classes, dtype=str) #convert on array\n",
    "\n",
    "print(\"Classes únicas no conjunto de dados:\", classes)\n",
    "\n",
    "list_labels = list(features.columns)\n",
    "print(\"\\nNomes dos atributos e classe:\\n\",list_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos construir as variáveis $X$ e $Y$, sendo que o processo classificação se resume em estimar a função $f$ na relação $Y=f(X)+\\epsilon$, onde $\\epsilon$ é o erro, que tem distribuição normal com média igual a zero e variância $\\sigma^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Obtendo a coluna de classes\n",
    "Y = np.array(features[list_labels[-1]], dtype=str)\n",
    "\n",
    "#Remove the labels from the features\n",
    "#axis 1 refers to the columns\n",
    "features = features.drop(list_labels[-1], axis = 1)\n",
    "\n",
    "#Convert to numpy array\n",
    "X = np.array(features)\n",
    "\n",
    "features.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificando o balanceamento das classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = np.unique(Y)\n",
    "ncl = np.zeros(len(cl))\n",
    "for i in np.arange(0, len(cl)):\n",
    "    a = Y == cl[i]\n",
    "    ncl[i] = len(Y[a])\n",
    "print(ncl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = np.arange(0, len(cl))\n",
    "plt.bar(numbers, ncl, alpha=.75)\n",
    "plt.xticks(numbers, cl)\n",
    "plt.title('Número de elementos em cada classe')\n",
    "plt.show(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving feature names for later use\n",
    "feature_list = list(features.columns)\n",
    "print(feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjuntos de teste e treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para treinar o classificador, precisamos definir o conjunto de teste e treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data into training and testing sets\n",
    "p = 0.7\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size = 1-p, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir desses dados, podemos realizar o processo de classificação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - No caso do classificador Knn, verifique o efeito do parâmetro k na classificação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### k-vizinhos\n",
    "\n",
    "Podemos realizar a classificação usando a biblioteca scikit-learn (https://scikit-learn.org). As métricas possíveis podem ser vistas em: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "vscore = []\n",
    "vk = []\n",
    "for k in np.arange(1, 15):\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    # Train the model using the training sets\n",
    "    model.fit(train_x,train_y)\n",
    "    #Predict Output\n",
    "    pred_y = model.predict(test_x)\n",
    "    score = accuracy_score(pred_y, test_y)\n",
    "    vscore.append(score)\n",
    "    vk.append(k)\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(vk, vscore, marker='s', linestyle='-', color=\"blue\", linewidth=2.5)\n",
    "plt.xlabel(\"k\", fontsize=20)\n",
    "plt.ylabel(\"Accuracy\", fontsize=20)\n",
    "plt.grid(True)\n",
    "plt.show(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 – Compare\tos\tclassificadores:\n",
    "- ### knn (melhor\tk\tobservado\tno\titem\tanterior)\n",
    "- ### Decisão\tBayesiana\n",
    "- ### Naive\tBayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificador Bayesiano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos considerar o caso paramétrico, assumindo que cada variável está distribuída de acordo com uma distribuição Normal.\n",
    "\n",
    "Já selecionamos os conjuntos de treinamento e teste. No conjunto de treinamento, vamos calcular a média e desvio padrão de cada atributo para cada classe. A seguir, reaizamos a classificação, dos dados usando a teoria da decisão Bayesiana, isto é: X∈Ci se, e somente se, P(Ci|X)=maxP(Cj|X) para todo j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "#matrix to store the probabilities\n",
    "P = pd.DataFrame(data=np.zeros((train_x.shape[0], len(classes))), columns= classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(0, len(classes)):\n",
    "    #elements tem todos os identificadores dos exemplos do conjunto de treinamento cujo rótulo é classe[i] \n",
    "    elements = tuple(np.where(train_y == classes[i]))\n",
    "    #Z contém todos os exemplos do conjunto de treinamento cujo rótulo é classe[i]\n",
    "    Z = train_x[elements,:][0]\n",
    "    #calcula a média por coluna(axis = 0)\n",
    "    m = np.mean(Z, axis = 0)\n",
    "    #calcula a covariancia da transposta de Z\n",
    "    cv = np.cov(np.transpose(Z))\n",
    "    #para cada exemplo do conjunto de teste\n",
    "    for j in np.arange(0, test_x.shape[0]):\n",
    "        #pega cada exemplo do conjunto de teste(todos os atributos)\n",
    "        x = test_x[j,:]\n",
    "        # probability density function for multivariate_normal is\n",
    "        #f(x) = \\frac{1}{\\sqrt{(2 \\pi)^k \\det \\Sigma}} \\exp\\left( -\\frac{1}{2} (x - \\mu)^T \\Sigma^{-1} (x - \\mu) \\right),\n",
    "        pj = multivariate_normal.pdf(x, mean=m, cov=cv)\n",
    "        P[classes[i]][j] = pj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = []\n",
    "#np.array(test_x.shape[0], dtype=str)\n",
    "#para cada exemplo do conjunto de teste \n",
    "for i in np.arange(0, test_x.shape[0]):\n",
    "    #pegar o identificador da coluna com maior probabilidade de cada exemplo\n",
    "    c = np.argmax(np.array(P.iloc[[i]]))\n",
    "    pred_y.append(classes[c])\n",
    "pred_y = np.array(pred_y, dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "score_bayes = accuracy_score(pred_y, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos considerar a biblioteca scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = gnb.predict(test_x)\n",
    "score_GNB = accuracy_score(pred_y, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A matriz de confusão:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acurácias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Acurácias:\\n\")\n",
    "print(\"\\tKNN para k = 1: \\t\\t%.4f\" % vscore[0])\n",
    "print(\"\\tDecisão Bayesiana: \\t\\t%.4f\" % score_bayes)\n",
    "print(\"\\tNaive Bayes: \\t\\t\\t%.4f\"% score_GNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível concluir que o algoritmo KNN, para k = 1 vizinhos, teve maior acurácia entre os algoritmos analisados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 – Verifique\to\tefeito\tda\tnormalização\t(atributos\tem\t[0,1])\te\tpadronização (atributos\tcom\tmédia\t0\te\tvariância\t1)\tdos\tdados.\tCompare\tos\tcasos\tsem\tprocessamento,\tcom\tpadronização\te\tcom\tnormalização\tpara\tos\tclassificadores:\n",
    "- ### knn\t(melhor\tk\tobservado\tno\titem\tanterior)\n",
    "- ### Decisão\tBayesiana\n",
    "- ### Naive\tBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bibliotecas para normalização e padronização\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-vizinhos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tipo:\n",
    "# 0 sem processamento\n",
    "# 1 com padronização\n",
    "# 2 com normalização\n",
    "def acuraciaKnnValor(features, tipo=0, p=0.7, metric='euclidean', k=1, dist=2):    \n",
    "    X = np.array(features, dtype=float)\n",
    "    #se quisermos a acurácia com padronização \n",
    "    if tipo == 1:\n",
    "        scaler = StandardScaler().fit(X)\n",
    "        X = scaler.transform(X)\n",
    "        \n",
    "    if tipo == 2:\n",
    "        scaler = MinMaxScaler(feature_range=(0,1))\n",
    "        scaler.fit(X)\n",
    "        X = scaler.transform(X)\n",
    "        \n",
    "    train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=1-p, random_state=42)\n",
    "    \n",
    "    model = KNeighborsClassifier(n_neighbors=k, p=dist, metric=metric)\n",
    "    # Train the model using the training sets\n",
    "    model.fit(train_x,train_y)\n",
    "    #Predict Output\n",
    "    pred_y = model.predict(test_x) \n",
    "    score = accuracy_score(pred_y, test_y)\n",
    "    return score\n",
    "\n",
    "print('Acurácia sem processamento:\\t', acuraciaKnnValor(features, tipo=0))\n",
    "print('Acurácia com padronização:\\t', acuraciaKnnValor(features, tipo=1))\n",
    "print('Acurácia com normalização:\\t', acuraciaKnnValor(features, tipo=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificador Bayesiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tipo:\n",
    "# 0 sem processamento\n",
    "# 1 com padronização\n",
    "# 2 com normalização\n",
    "def acuraciaBayesValor(features, tipo=0, p=0.7):\n",
    "    \n",
    "    X = np.array(features, dtype=float)\n",
    "    if tipo == 1:\n",
    "        scaler = StandardScaler().fit(X)\n",
    "        X = scaler.transform(X)\n",
    "    \n",
    "    if tipo == 2:\n",
    "        scaler = MinMaxScaler(feature_range=(0,1))\n",
    "        scaler.fit(X)\n",
    "        X = scaler.transform(X)\n",
    "    \n",
    "    train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=1-p, random_state=42)\n",
    "    P = pd.DataFrame(data=np.zeros((test_x.shape[0], len(classes))), columns = classes)\n",
    "    for i in np.arange(0, len(classes)):\n",
    "        elements = tuple(np.where(train_y == classes[i]))\n",
    "        Z = train_x[elements,:][0]\n",
    "        m = np.mean(Z, axis = 0)\n",
    "        cv = np.cov(np.transpose(Z))\n",
    "        for j in np.arange(0,test_x.shape[0]):\n",
    "            x = test_x[j,:]\n",
    "            pj = multivariate_normal.pdf(x, mean=m, cov=cv)\n",
    "            P[classes[i]][j] = pj\n",
    "    \n",
    "    pred_y = []\n",
    "    for i in np.arange(0, test_x.shape[0]):\n",
    "        c = np.argmax(np.array(P.iloc[[i]]))\n",
    "        pred_y.append(classes[c])\n",
    "    pred_y = np.array(pred_y, dtype=str)\n",
    "    \n",
    "    score = accuracy_score(pred_y, test_y)\n",
    "    return score\n",
    "\n",
    "print('Acurácia sem processamento:\\t', acuraciaBayesValor(features, tipo=0))\n",
    "print('Acurácia com padronização:\\t', acuraciaBayesValor(features, tipo=1))\n",
    "print('Acurácia com normalização:\\t', acuraciaBayesValor(features, tipo=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tipo:\n",
    "# 0 sem processamento\n",
    "# 1 com padronização\n",
    "# 2 com normalização\n",
    "def acuraciaNaiveBayesValor(features, tipo=0, p=0.7):\n",
    "    \n",
    "    X = np.array(features, dtype=float)\n",
    "    if tipo == 1:\n",
    "        scaler = StandardScaler().fit(X)\n",
    "        X = scaler.transform(X)\n",
    "    \n",
    "    if tipo == 2:\n",
    "        scaler = MinMaxScaler(feature_range=(0,1))\n",
    "        scaler.fit(X)\n",
    "        X = scaler.transform(X)\n",
    "    \n",
    "    train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=1-p, random_state=42)\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(train_x, train_y)\n",
    "    \n",
    "    pred_y = gnb.predict(test_x)\n",
    "    score = accuracy_score(pred_y, test_y)\n",
    "    return score\n",
    "\n",
    "print('Acurácia sem processamento:\\t', acuraciaNaiveBayesValor(features, tipo=0))\n",
    "print('Acurácia com padronização:\\t', acuraciaNaiveBayesValor(features, tipo=1))\n",
    "print('Acurácia com normalização:\\t', acuraciaNaiveBayesValor(features, tipo=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 – Mostre a matriz de correlação entre os atributos. Considere os atributos com menor correlação (por exemplo, menor do que 0.5). Realize a classificação novamente apenas com esses atributos. A acurácia melhora?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A matriz de correlação entre as variáveis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "corr = features.corr()\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(corr, annot=True)\n",
    "#Plot Correlation Matrix using Matplotlib\n",
    "# plt.figure(figsize=(7,7))\n",
    "# plt.imshow(corr, cmap='Blues', interpolation='none', aspect='auto')\n",
    "# plt.colorbar()\n",
    "# plt.xticks(range(len(corr)), corr.columns, rotation='vertical')\n",
    "# plt.yticks(range(len(corr)), corr.columns);\n",
    "# plt.suptitle('Correlation between variables', fontsize=15, fontweight='bold')\n",
    "# plt.grid(False)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim, para identificarmos as variáveis correlacionadas, usamos um laço for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.5\n",
    "var = []\n",
    "for i in corr.columns:\n",
    "    for j in corr.columns:\n",
    "        if(i != j):\n",
    "            if np.abs(corr[i][j]) < p:\n",
    "                var.append([i, j])\n",
    "print('Variáveis com correlação menor que 0.5:\\n', var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7\t– Verifique\tqual\tdos\tclassificadores\té\tmais\trobusto\tcom\trelação\tà\tpresença\tde ruídos.\tPara\tisso:\t\n",
    "- ### Aplique\ta\tnormalização\tdos\tdados\tpara\tque\tos\tatributos\tapresentem\tmédia\tigual\ta\tzero\te\tvariância\tigual\ta\t1.\n",
    "- ### Inclua\tem\tX%\tdos\tatributos,\tum\tvalor\tnormalmente\tdistribuído\tcom\tmédia\tzero\te\tvariância\t1.\tConsidere\ttoda\ta\tmatriz\tdos\tdados,\tsorteando uma\tposição\tda\tmatriz\tde\tforma\taleatória.\n",
    "- ### Varie\to\tnível\tde\truído,\tde\t0\ta\t50%\t(em\tpassos\tde\t5%)\te\tavalie\tcomo\tmuda\ta\tclassificação.\tConstrua\tum\tgráfico\tde\tX% de\truído versus\tporcentagem\tde\tclassificação\tcorreta.\tColoque\ta\tmédia\te\to\tdesvio\tpadrão\tcalculados\ta\tpartir\tde\tao\tmenos\t10\tsimulações.\tConsidere\t70%\tdos\tdados\tno\tconjunto\tde\ttreinamento.\n",
    "- ### Discuta os\tresultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insereRuidoEmCadaClassificador(X_padr, num_pos):\n",
    "    plot_porcentagens = []\n",
    "    acur_knn = []\n",
    "    acur_bayesiano = []\n",
    "    acur_naive_bayes = []\n",
    "\n",
    "    #Definindo o X% -> indo de 0 a 50%\n",
    "    for porcentagemX in np.arange(0, 51, 5):\n",
    "\n",
    "        plot_porcentagens.append(str(porcentagemX) + \"%\")\n",
    "\n",
    "        #print(\"Porcentagem dos dados a serem substituídos:\", porcentagemX)\n",
    "        num_sorted_pos = int(np.around(num_pos * porcentagemX / 100))\n",
    "        #print(\"Número de posições a serem escolhidas:\\n\", num_sorted_pos, end='\\n\\n')\n",
    "\n",
    "        #Set que guardará as x% posições randômicas da matriz\n",
    "        posicoes = set()\n",
    "\n",
    "        #Escolha aleatória das posições da matriz e inserindo no set\n",
    "        while len(posicoes) != num_sorted_pos:\n",
    "            num_rand_i = np.random.randint(0, np.shape(X_padr)[0])\n",
    "            num_rand_j = np.random.randint(0, np.shape(X_padr)[1])\n",
    "            num_rand = tuple([num_rand_i, num_rand_j])\n",
    "            #print(num_rand)\n",
    "            posicoes.add(num_rand)\n",
    "\n",
    "        #Geração do conjunto de dados normalmente distribuído\n",
    "        num_normal = np.random.normal(0, 1, num_sorted_pos)\n",
    "\n",
    "        #Inserção do conjunto de dados normalmente distribuído no conjunto original\n",
    "        for num, pos in zip(num_normal, posicoes):\n",
    "            X_padr[pos[0]][pos[1]] = num\n",
    "\n",
    "        acur_knn.append(100*acuraciaKnnValor(X_padr))\n",
    "        acur_bayesiano.append(100*acuraciaBayesValor(X_padr))\n",
    "        acur_naive_bayes.append(100*acuraciaNaiveBayesValor(X_padr))\n",
    "    \n",
    "    return plot_porcentagens, acur_knn, acur_bayesiano, acur_naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicando padronização\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_padr = scaler.transform(X)\n",
    "\n",
    "#Verificando média e variância\n",
    "np.set_printoptions(precision=2)\n",
    "print(\"Lista das médias de cada coluna: %s\" % np.around(np.mean(X_padr, axis=0)))\n",
    "print(\"Lista das variâncias de cada coluna: %s\" % np.var(X_padr, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtendo o número de posições da matriz\n",
    "print(\"Dados: %s\" % X_padr, end='\\n\\n')\n",
    "num_pos = np.shape(X_padr)[0] * np.shape(X_padr)[1]\n",
    "print(\"Tamanho da matriz:\\n\", np.shape(X_padr), end='\\n\\n')\n",
    "print(\"Número de posições na matriz:\\n\", num_pos, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Atenção: essa célula demora cerca de 3 minutos para concluir\n",
    "\n",
    "#Obtendo 10 simulações diferentes\n",
    "plot_porcentagens = []\n",
    "acur_knn = []\n",
    "acur_bayesiano = []\n",
    "acur_naive_bayes = []\n",
    "\n",
    "#Inserindo nas listas acima para posterior análise\n",
    "for i in range(10):\n",
    "    px, ak, acb, anb = insereRuidoEmCadaClassificador(X_padr, num_pos)\n",
    "    plot_porcentagens.append(px)\n",
    "    acur_knn.append(ak)\n",
    "    acur_bayesiano.append(acb)\n",
    "    acur_naive_bayes.append(anb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Configurando matplotlib\n",
    "fig = plt.figure(figsize=(15,30))\n",
    "\n",
    "#Plotando os 10 gráficos para cada simulação\n",
    "for i in range(10):\n",
    "    px = plot_porcentagens[i]\n",
    "    ak = acur_knn[i]\n",
    "    acb = acur_bayesiano[i]\n",
    "    anb = acur_naive_bayes[i]\n",
    "    #Inserindo num gráfico a porcentagem x acurácia    \n",
    "    fig.add_subplot(5, 2, i+1)\n",
    "    \n",
    "    plt.xlabel('Porcentagem dos dados de ruído')\n",
    "    plt.ylabel('Porcentagem de acurácia')\n",
    "    plt.grid(True)\n",
    "        \n",
    "    plt.plot(px, ak, label='KNN para k = 1')\n",
    "    plt.plot(px, acb, label='Classificador Bayesiano')\n",
    "    plt.plot(px, anb, label='Naive Bayes')\n",
    "    plt.legend(loc='best')\n",
    "    \n",
    "\n",
    "plt.show(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Média e desvio padrão para cada classificador\n",
    "print(\"==== Cálculo de médias e desvio padrão para cada classificador ====\\n\")\n",
    "print(\"\\t\\t\\tMédia\\t\\tDesvio padrão\")\n",
    "print(\"KNN com k = 1\\t\\t%.4f\\t\\t%.4f\" % (np.mean(acur_knn), np.var(acur_knn)))\n",
    "print(\"Classificador Bayesiano\\t%.4f\\t\\t%.4f\" % (np.mean(acur_bayesiano), np.var(acur_bayesiano)))\n",
    "print(\"Naive Bayes\\t\\t%.4f\\t\\t%.4f\" % (np.mean(acur_naive_bayes), np.var(acur_naive_bayes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisando os dados listados acima (média, desvio padrão e os gráficos plotados), podemos ver que o classificador KNN para k = 1 se manteve com maior acurácia na maioria das simulações feitas, além de ter média de acurácia maior. Como é um algoritmo pouco elaborado e considera somente dados próximos ao dado analisado, não há consistência clara na média, concretizado pelo seu maior desvio padrão em relação aos dois outros classificadores.\n",
    "\n",
    "Caso fosse necessário escolher um algoritmo de classificação, a melhor escolha seria o Classificador Bayesiano, porque sua média de acurácia é muito próxima ao do melhor classificador (no caso, KNN com k = 1) e seu desvio padrão é o menor entre os três algoritmos analisados, o que indica maior consistência na classificação do dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 – No caso do classificador Naive Bayes, é possível considerar diferentes funções para estimar as probabilidades. Compare os casos: (i) Gaussian Naive Bayes, (ii) multinomial Naive Bayese (iii)Bernoulli Naive Bayes. Considere os casos com e sem normalização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#tipo:\n",
    "# 0 sem processamento\n",
    "# 1 com padronização\n",
    "# 2 com normalização\n",
    "def acuraciaMultinomialNaiveBayesValor(features, tipo=0, p=0.7): \n",
    "    \n",
    "    X = np.array(features, dtype=float)\n",
    "    if tipo == 1:\n",
    "        scaler = StandardScaler().fit(X)\n",
    "        X = scaler.transform(X)\n",
    "    \n",
    "    if tipo == 2:\n",
    "        scaler = MinMaxScaler(feature_range=(0,1))\n",
    "        scaler.fit(X)\n",
    "        X = scaler.transform(X)\n",
    "    \n",
    "    train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=1-p, random_state=42)\n",
    "    mnb = MultinomialNB()\n",
    "    mnb.fit(train_x, train_y)\n",
    "    pred_y = mnb.predict(test_x)\n",
    "    score_MNB = accuracy_score(pred_y, test_y)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "#tipo:\n",
    "# 0 sem processamento\n",
    "# 1 com padronização\n",
    "# 2 com normalização\n",
    "def acuraciaBernoulliNaiveBayesValor(features, tipo=0, p=0.7): \n",
    "    \n",
    "    X = np.array(features, dtype=float)\n",
    "    if tipo == 1:\n",
    "        scaler = StandardScaler().fit(X)\n",
    "        X = scaler.transform(X)\n",
    "    \n",
    "    if tipo == 2:\n",
    "        scaler = MinMaxScaler(feature_range=(0,1))\n",
    "        scaler.fit(X)\n",
    "        X = scaler.transform(X)\n",
    "    \n",
    "    train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=1-p, random_state=42)\n",
    "    bnb = BernoulliNB()\n",
    "    bnb.fit(train_x, train_y)\n",
    "    pred_y = bnb.predict(test_x)\n",
    "    score_BNB = accuracy_score(pred_y, test_y)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tipo:\n",
    "# 0 sem processamento\n",
    "# 1 com padronização\n",
    "# 2 com normalização\n",
    "def acuraciaMultinomialNaiveBayesValor(features, tipo=0, p=0.7):\n",
    "    \n",
    "    X = np.array(features, dtype=float)\n",
    "    if tipo == 1:\n",
    "        scaler = StandardScaler().fit(X)\n",
    "        X = scaler.transform(X)\n",
    "    \n",
    "    if tipo == 2:\n",
    "        scaler = MinMaxScaler(feature_range=(0,1))\n",
    "        scaler.fit(X)5\n",
    "        X = scaler.transform(X)\n",
    "    \n",
    "    train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=1-p, random_state=42)\n",
    "    mnb = MultinomialNB()\n",
    "    mnb.fit(train_x, train_y)\n",
    "    pred_y = mnb.predict(test_x)\n",
    "    score_MNB = accuracy_score(pred_y, test_y)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Acurácias para o Naive Bayes sem normalização:\\n\")\n",
    "print(\"\\tGaussian Nai5ve Bayes: \\t%.4f\" % acuraciaNaiveBayesValor(features, tipo=0, p=0.7))\n",
    "print(\"\\tMultinomial Naive Bayes: %.4f\" % acuraciaMultinomialNaiveBayesValor(features, tipo=0, p=0.7))\n",
    "print(\"\\tBernoulli Naive Bayes: \\t%.54f\"% acuraciaBernoulliNaiveBayesValor(features, tipo=0, p=0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Acurácias para o Naive Bayes com normalização:\\n\")\n",
    "print(\"\\tGau5ssian Naive Bayes: \\t%.4f\" % acuraciaNaiveBayesValor(features, tipo=2, p=0.7))\n",
    "#MultinomialNB assumes that features have multinomial distribution which is a generalization of the binomial distribution. \n",
    "#Neither binomial nor multinomial distributions can contain negative values.\n",
    "#print(\"\\tMultinomial Naive Bayes: %.4f\" % acuraciaMultinomialNaiveBayesValor(features, tipo=1, p=0.7))\n",
    "print(\"\\tBernoulli Naive Bayes: \\t%.4f\"% acuraciaBernoulliNaiveBayesValor(features, tipo=2, p=0.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 – No caso do Knn, compare as classificações usando diferentes métricas. Varie k e mostre as curvas (em um mesmo plot) para as distâncias euclidiana, Manhattan, Chebyshev e Minkowski (p=1.5, p = 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Acurácia\")\n",
    "\n",
    "dists = ['euclidean', 'manhattan', 'chebyshev']\n",
    "for m in dists:\n",
    "    acur = []\n",
    "    k_list = []\n",
    "    for k in range(1, 15):\n",
    "        acur.append(acuraciaKnnValor(features, tipo=0, p=0.7, metric=m, k=k))\n",
    "        k_list.append(k)\n",
    "    plt.plot(k_list, acur, label=m, linewidth=2.5)\n",
    "\n",
    "p_list = [1.5, 3]\n",
    "for p_valor in p_list:\n",
    "    acur = []\n",
    "    k_list = []\n",
    "    for k in range(1, 15):\n",
    "        acur.append(acuraciaKnnValor(features, tipo=0, p=0.7, metric='minkowski', k=k, dist=p_valor))\n",
    "        k_list.append(k)\n",
    "    plt.plot(k_list, acur, label='minkowski_'+str(p_valor), linewidth=2.5)    \n",
    "    \n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10\t– Faça\tum\tgráfico\tda\tfração\tde\telementos\tno\tconjunto\tde\ttreinamento\t(10%\taté\t90%\tem\tpassos\tde\t10%)\tversus\tacurácia\tpara\tos\tclassificadores:\n",
    "- ### knn\t(melhor\tk\tobservado\tanteriormente)\n",
    "- ### Naive\tBayes\n",
    "- ### Decisão\tBayesiana\n",
    "## Considere os\tcasos com e sem padronização."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-vizinhos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracia_sem = []\n",
    "acuracia_com = []\n",
    "list_p = []\n",
    "for i in range(1, 10):\n",
    "    list_p.append(i/10)\n",
    "    acuracia_sem.append(acuraciaKnnValor(features, tipo=0, p=i/10, k=1))\n",
    "    acuracia_com.append(acuraciaKnnValor(features, tipo=1, p=i/10, k=1))\n",
    "\n",
    "print(\"Gráfico da acurácia em função da fração de elementos no conjunto de treinamento:\")\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.xlabel(\"Fração de elementos no conjunto de treinamento\")\n",
    "plt.ylabel(\"Acurácia\")\n",
    "plt.plot(list_p, acuracia_sem, label = 'sem padronização', linewidth=2.5)\n",
    "plt.plot(list_p, acuracia_com, label = 'com padronização', linewidth=2.5)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.grid(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificador bayesiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracia_sem = []\n",
    "acuracia_com = []\n",
    "list_p = []\n",
    "#não funciona com 10% pois a matriz se torna singular e ocorre um erro com o método pdf\n",
    "for i in range(2, 10):    \n",
    "    list_p.append(i/10)\n",
    "    acuracia_sem.append(acuraciaBayesValor(features=features, tipo=0, p=i/10))\n",
    "    acuracia_com.append(acuraciaBayesValor(features=features, tipo=1, p=i/10))\n",
    "    \n",
    "print(\"Gráfico da acurácia em função da fração de elementos no conjunto de treinamento:\")\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.xlabel(\"Fração de elementos no conjunto de treinamento\")\n",
    "plt.ylabel(\"Acurácia\")\n",
    "plt.plot(list_p, acuracia_sem, label = 'sem padronização', linewidth=2.5)\n",
    "plt.plot(list_p, acuracia_com, label = 'com padronização', linewidth=2.5)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracia_sem = []\n",
    "acuracia_com = []\n",
    "list_p = []\n",
    "for i in range(1, 10):\n",
    "    list_p.append(i/10)\n",
    "    acuracia_sem.append(acuraciaNaiveBayesValor(features=features, tipo=0, p=i/10))\n",
    "    acuracia_com.append(acuraciaNaiveBayesValor(features=features, tipo=1, p=i/10))\n",
    "    \n",
    "print(\"Gráfico da acurácia em função da fração de elementos no conjunto de treinamento:\")\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.xlabel(\"Fração de elementos no conjunto de treinamento\")\n",
    "plt.ylabel(\"Acurácia\")\n",
    "plt.plot(list_p, acuracia_sem, label = 'sem padronização', linewidth=2.5)\n",
    "plt.plot(list_p, acuracia_com, label = 'com padronização', linewidth=2.5)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.grid(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
